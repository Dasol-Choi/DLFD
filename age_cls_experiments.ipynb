{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "UWvuBOPACCza"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !wget https://postechackr-my.sharepoint.com/:u:/g/personal/dongbinna_postech_ac_kr/EbMhBPnmIb5MutZvGicPKggBWKm5hLs0iwKfGW7_TwQIKg?download=1 -O custom_korean_family_dataset_resolution_128.zip\n",
    "# !unzip custom_korean_family_dataset_resolution_128.zip -d ./custom_korean_family_dataset_resolution_128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qJl1GEjIDTuA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from trainer import train, test\n",
    "from evaluation.mia import MIA\n",
    "from evaluation.accuracy import calculate_accuracy, calculate_all_accuracies\n",
    "from model import load_model\n",
    "from MUFAC_loader import get_data_loaders\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 10025\n",
      "Number of test samples: 1504\n",
      "Number of val samples: 1539\n",
      "Number of retained train samples: 8525\n",
      "Number of forgotten train samples: 1500\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "train_meta_data_path = \"/home/dasol/Unlearning/custom_korean_family_dataset_resolution_128_2/custom_train_dataset.csv\"\n",
    "train_image_directory = \"/home/dasol/Unlearning/custom_korean_family_dataset_resolution_128_2/train_images\"\n",
    "\n",
    "val_meta_data_path = \"/home/dasol/Unlearning/custom_korean_family_dataset_resolution_128_2/custom_val_dataset.csv\"\n",
    "val_image_directory = \"/home/dasol/Unlearning/custom_korean_family_dataset_resolution_128_2/val_images\"\n",
    "\n",
    "test_meta_data_path = \"/home/dasol/Unlearning/custom_korean_family_dataset_resolution_128_2/custom_test_dataset.csv\"\n",
    "test_image_directory = \"/home/dasol/Unlearning/custom_korean_family_dataset_resolution_128_2/test_images\"\n",
    "\n",
    "batch_size = 32\n",
    "data_loaders = get_data_loaders(\n",
    "    train_meta_data_path, train_image_directory,\n",
    "    val_meta_data_path, val_image_directory,\n",
    "    test_meta_data_path, test_image_directory, batch_size\n",
    ")\n",
    "\n",
    "print(f\"Number of training samples: {len(data_loaders['train'].dataset)}\")\n",
    "print(f\"Number of test samples: {len(data_loaders['test'] .dataset)}\")\n",
    "print(f\"Number of val samples: {len(data_loaders['val'].dataset)}\")\n",
    "print(f\"Number of retained train samples: {len(data_loaders['retain_train'].dataset)}\")\n",
    "print(f\"Number of forgotten train samples: {len(data_loaders['forget_train'].dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = load_model(8, device, model_path=None)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=200)\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "history = []\n",
    "accuracy = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, data_loaders['train'], criterion, optimizer, scheduler, device, epoch)\n",
    "    val_loss, val_acc = test(model, data_loaders['val'], criterion, device)\n",
    "    history.append((train_loss, train_acc))\n",
    "    accuracy.append((val_loss, val_acc))\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        print(\"[Info] best test accuracy!\")\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        #torch.save(model.state_dict(), f'checkpoints/resnet/best_{epoch + 1}_age_original.pth')\n",
    "\n",
    "#torch.save(model.state_dict(), f'checkpoints/resnet/last_{num_epochs}_age_original.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6cmAUsZsQJM2",
    "outputId": "fe67b32e-7afb-4dd8-b37f-1dffa710e302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: {'Loss': 0.0374256043516575, 'Acc': 0.6329787234042553, 'Top-2 Acc': 0.8803191489361702}\n",
      "MIA: {'MIA Regression Accuracy': 0.7618180241131061, 'MIA CV Accuracy': 0.6923588039867109, 'Forgetting Score': 0.1923588039867109}\n",
      "Final score: 0.6241305577154167\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path =  'checkpoint/last_100_age_original.pth'\n",
    "model = load_model(8, device, model_path)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "test_acc = calculate_accuracy(model, data_loaders['test'], criterion, device)\n",
    "mia = MIA(model, data_loaders[\"retain_test\"], data_loaders['forget_test'], data_loaders['test'], device)\n",
    "final_score = (test_acc[\"Acc\"] + 1 - abs(mia[\"Forgetting Score\"] * 2)) / 2\n",
    "print(f'Test Acc: {test_acc}')\n",
    "print(f'MIA: {mia}')\n",
    "print(f'Final score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Retrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "retrained_model = load_model(8, device, model_path=None)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(retrained_model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=200)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_epochs = 100\n",
    "best_val_acc = 0\n",
    "best_epoch = 0\n",
    "\n",
    "history = []\n",
    "accuracy = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(retrained_model, data_loaders['retain_train'], criterion, optimizer, scheduler, device, epoch)\n",
    "    val_loss, val_acc = test(retrained_model, data_loaders['val'], criterion, device)\n",
    "    history.append((train_loss, train_acc))\n",
    "    accuracy.append((val_loss, val_acc))\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        print(\"[Info] best test accuracy!\")\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        #torch.save(retrained_model.state_dict(), f'checkpoint/best_{epoch + 1}_age_retrained.pth')\n",
    "\n",
    "#torch.save(retrained_model.state_dict(), f'checkpoint/last_{num_epochs}_age_retrained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: {'Loss': 0.037642640834476084, 'Acc': 0.6083776595744681, 'Top-2 Acc': 0.8656914893617021}\n",
      "MIA: {'MIA Regression Accuracy': 0.7678896695290138, 'MIA CV Accuracy': 0.5548172757475083, 'Forgetting Score': 0.054817275747508276}\n",
      "Final score: 0.7493715540397258\n"
     ]
    }
   ],
   "source": [
    "model_path = 'checkpoint/last_100_age_retrained.pth'\n",
    "retrained_model = load_model(8, device, model_path)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "test_acc = calculate_accuracy(retrained_model, data_loaders['test'], criterion, device)\n",
    "mia = MIA(retrained_model, data_loaders[\"retain_test\"], data_loaders['forget_test'], data_loaders['test'], device)\n",
    "final_score = (test_acc[\"Acc\"] + 1 - abs(mia[\"Forgetting Score\"] * 2)) / 2\n",
    "print(f'Test Acc: {test_acc}')\n",
    "print(f'MIA: {mia}')\n",
    "print(f'Final score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unlearning Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1 - Training]\n",
      "[Batch: 80] running train loss: 0.010473815829027445, running train accuracy: 0.888671875\n",
      "[Batch: 160] running train loss: 0.00998851096665021, running train accuracy: 0.8935546875\n",
      "[Batch: 240] running train loss: 0.009844225030974485, running train accuracy: 0.89348965883255\n",
      "train loss: 0.009800257664446957, accuracy: 0.8932551145553589\n",
      "elapsed time: 15.528449296951294\n",
      "[Test]\n",
      "[Batch: 1] running test loss: 0.0499936044216156, running test accuracy: 0.59375\n",
      "test loss: 0.045445403005489673, accuracy: 0.5724496245384216\n",
      "elapsed time: 1.0893614292144775\n",
      "[Epoch: 2 - Training]\n",
      "[Batch: 80] running train loss: 0.008728485857136547, running train accuracy: 0.903124988079071\n",
      "[Batch: 160] running train loss: 0.008625717423274181, running train accuracy: 0.8994140625\n",
      "[Batch: 240] running train loss: 0.008521037284905712, running train accuracy: 0.9027343988418579\n",
      "train loss: 0.008530318191673748, accuracy: 0.9031084775924683\n",
      "elapsed time: 15.045075178146362\n",
      "[Test]\n",
      "[Batch: 1] running test loss: 0.04759373143315315, running test accuracy: 0.625\n",
      "test loss: 0.047057011051562174, accuracy: 0.5646523833274841\n",
      "elapsed time: 1.0029397010803223\n",
      "Test Acc: {'Loss': 0.0396959254557782, 'Acc': 0.6376329787234043, 'Top-2 Acc': 0.8969414893617021}\n",
      "MIA: {'MIA Regression Accuracy': 0.7671090294041114, 'MIA CV Accuracy': 0.6883720930232557, 'Forgetting Score': 0.18837209302325575}\n",
      "Final score: 0.6304443963384464\n"
     ]
    }
   ],
   "source": [
    "model_path =  'checkpoint/last_100_age_original.pth'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "finetune_model = load_model(8, device, model_path)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(finetune_model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "num_epochs=2\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(finetune_model, data_loaders['retain_train'], criterion, optimizer, scheduler, device, epoch)\n",
    "    val_loss, val_acc = test(finetune_model, data_loaders['val'], criterion, device)\n",
    "\n",
    "test_acc = calculate_accuracy(finetune_model, data_loaders['test'], criterion, device)\n",
    "mia = MIA(finetune_model, data_loaders[\"retain_test\"], data_loaders['forget_test'], data_loaders['test'], device)\n",
    "final_score = (test_acc[\"Acc\"] + 1 - abs(mia[\"Forgetting Score\"] * 2)) / 2\n",
    "print(f'Test Acc: {test_acc}')\n",
    "print(f'MIA: {mia}')\n",
    "print(f'Final score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CF-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1 - Training]\n",
      "[Batch: 80] running train loss: 0.011000621796119959, running train accuracy: 0.876171886920929\n",
      "[Batch: 160] running train loss: 0.010439964865508956, running train accuracy: 0.885937511920929\n",
      "[Batch: 240] running train loss: 0.010353822650116248, running train accuracy: 0.8878906965255737\n",
      "train loss: 0.010294202425437939, accuracy: 0.8877419233322144\n",
      "elapsed time: 11.836766481399536\n",
      "[Test]\n",
      "[Batch: 1] running test loss: 0.03943987563252449, running test accuracy: 0.59375\n",
      "test loss: 0.037975033626277396, accuracy: 0.6309840083122253\n",
      "elapsed time: 0.9689269065856934\n",
      "Epoch [1/2] - Train Loss: 0.0103, Train Accuracy: 0.89%\n",
      "Epoch [1/2] - Test Loss: 0.0380, Test Accuracy: 0.63%\n",
      "[Epoch: 2 - Training]\n",
      "[Batch: 80] running train loss: 0.009430807890021242, running train accuracy: 0.8960937857627869\n",
      "[Batch: 160] running train loss: 0.010034417739370837, running train accuracy: 0.891406238079071\n",
      "[Batch: 240] running train loss: 0.01028650209773332, running train accuracy: 0.8854166865348816\n",
      "train loss: 0.010275076113837905, accuracy: 0.8863343000411987\n",
      "elapsed time: 11.48568844795227\n",
      "[Test]\n",
      "[Batch: 1] running test loss: 0.039746325463056564, running test accuracy: 0.59375\n",
      "test loss: 0.03860155772417784, accuracy: 0.6223403811454773\n",
      "elapsed time: 0.9659271240234375\n",
      "Epoch [2/2] - Train Loss: 0.0103, Train Accuracy: 0.89%\n",
      "Epoch [2/2] - Test Loss: 0.0386, Test Accuracy: 0.62%\n",
      "Test Acc: {'Loss': 0.03860155772417784, 'Acc': 0.6223404255319149, 'Top-2 Acc': 0.879654255319149}\n",
      "MIA: {'MIA Regression Accuracy': 0.7617312863214503, 'MIA CV Accuracy': 0.683720930232558, 'Forgetting Score': 0.18372093023255798}\n",
      "Final score: 0.6274492825333995\n"
     ]
    }
   ],
   "source": [
    "from unlearn.cfk import cfk_train\n",
    "\n",
    "model_path =  'checkpoint/last_100_age_original.pth'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"CPU\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs=2\n",
    "cfk_model = load_model(8, device, model_path)\n",
    "cfk_model = cfk_train(cfk_model, data_loaders['retain_train'], data_loaders['test'], device, epochs)\n",
    "\n",
    "test_acc = calculate_accuracy(cfk_model, data_loaders['test'], criterion, device)\n",
    "mia = MIA(cfk_model, data_loaders[\"retain_test\"], data_loaders['forget_test'], data_loaders['test'], device)\n",
    "final_score = (test_acc[\"Acc\"] + 1 - abs(mia[\"Forgetting Score\"] * 2)) / 2\n",
    "print(f'Test Acc: {test_acc}')\n",
    "print(f'MIA: {mia}')\n",
    "print(f'Final score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EU-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unlearning Epoch [1/2] - Loss: 0.3320, Accuracy: 88.47%\n",
      "Unlearning Epoch [2/2] - Loss: 0.3204, Accuracy: 89.04%\n",
      "Test Acc: {'Loss': 0.03736931507654013, 'Acc': 0.629654255319149, 'Top-2 Acc': 0.8776595744680851}\n",
      "MIA: {'MIA Regression Accuracy': 0.7611241217798594, 'MIA CV Accuracy': 0.6893687707641196, 'Forgetting Score': 0.18936877076411962}\n",
      "Final score: 0.6254583568954548\n"
     ]
    }
   ],
   "source": [
    "from unlearn.euk import euk_unlearn\n",
    "\n",
    "epochs = 2\n",
    "model_path =  'checkpoint/last_100_age_original.pth'\n",
    "euk_model = load_model(8, device, model_path)\n",
    "euk_model = euk_unlearn(euk_model, data_loaders['retain_train'], device, epochs)\n",
    "\n",
    "test_acc = calculate_accuracy(euk_model, data_loaders['test'], criterion, device)\n",
    "mia = MIA(euk_model, data_loaders[\"retain_test\"], data_loaders['forget_test'], data_loaders['test'], device)\n",
    "final_score = (test_acc[\"Acc\"] + 1 - abs(mia[\"Forgetting Score\"] * 2)) / 2\n",
    "print(f'Test Acc: {test_acc}')\n",
    "print(f'MIA: {mia}')\n",
    "print(f'Final score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NegGrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NegGrad Epoch [1/1] Loss: 0.846\n",
      "Test Acc: {'Loss': 0.11845020474271571, 'Acc': 0.4115691489361702, 'Top-2 Acc': 0.7054521276595744}\n",
      "MIA: {'MIA Regression Accuracy': 0.7394396738659034, 'MIA CV Accuracy': 0.4750830564784054, 'Forgetting Score': 0.024916943521594626}\n",
      "Final score: 0.6808676309464905\n"
     ]
    }
   ],
   "source": [
    "from unlearn.neg_grad import neggrad_unlearn\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.gpu = 0\n",
    "        self.lr = 0.001\n",
    "        self.momentum = 0.9\n",
    "        self.weight_decay = 5e-4\n",
    "        self.num_classes = 8\n",
    "        self.epochs = 1\n",
    "        self.device = torch.device(f\"cuda:{self.gpu}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "args = Args()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_path =  'checkpoint/last_100_age_original.pth'\n",
    "neggrad_model = load_model(8, args.device, model_path)\n",
    "neggrad_unlearn(neggrad_model, data_loaders['forget_train'], criterion, args)\n",
    "\n",
    "test_acc = calculate_accuracy(neggrad_model, data_loaders['test'], criterion, args.device)\n",
    "mia = MIA(neggrad_model, data_loaders[\"retain_test\"], data_loaders['forget_test'], data_loaders['test'], args.device)\n",
    "final_score = (test_acc[\"Acc\"] + 1 - abs(mia[\"Forgetting Score\"] * 2)) / 2\n",
    "print(f'Test Acc: {test_acc}')\n",
    "print(f'MIA: {mia}')\n",
    "print(f'Final score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNSIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1] - Noise Loss: 2923.9854\n",
      "Impair Step - Train loss 1: 2.9501, Train Acc: 15.40%\n",
      "Performance of Impaired Model on Forget Samples\n",
      "Test Acc: {'Loss': 0.07558805432091369, 'Acc': 0.2646276595744681, 'Top-2 Acc': 0.3151595744680851}\n",
      "Impaired MIA : {'MIA Regression Accuracy': 0.7394396738659034, 'MIA CV Accuracy': 0.5255813953488372, 'Forgetting Score': 0.025581395348837188}\n",
      "Repair Step - Train loss 1: 1.2748, Train Acc: 47.91%\n",
      "Repair Step - Train loss 2: 2.4218, Train Acc: 100.87%\n",
      "Performance of Repaired Model on Forget Samples\n",
      "Test Acc: {'Loss': 0.042461668478047596, 'Acc': 0.49069148936170215, 'Top-2 Acc': 0.726063829787234}\n",
      "Repaired MIA: {'MIA Regression Accuracy': 0.739613149449215, 'MIA CV Accuracy': 0.5308970099667774, 'Forgetting Score': 0.030897009966777356}\n",
      "Final score: 0.7144487347140738\n"
     ]
    }
   ],
   "source": [
    "from unlearn.unsir import Noise, generate_error_maximizing_noise, impair_step, repair_step\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.alpha = 0.1\n",
    "        self.num_classes = 8\n",
    "        self.device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.impair_epochs = 1\n",
    "        self.repair_epochs = 2\n",
    "        self.lr = 0.001\n",
    "\n",
    "args = Args()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_path = 'checkpoint/last_100_age_original.pth'\n",
    "unsir_model = load_model(8, device, model_path)\n",
    "\n",
    "noise = generate_error_maximizing_noise(unsir_model, data_loaders['forget_train'], args.device, args.impair_epochs)\n",
    "\n",
    "# Impair Step\n",
    "noisy_data = [(noise()[i % noise().size(0)], data_loaders['forget_train'].dataset[i][1]) for i in range(len(data_loaders['forget_train'].dataset))]\n",
    "noisy_loader = DataLoader(noisy_data, batch_size=128, shuffle=True)\n",
    "impair_step(unsir_model, noisy_loader, args.device, args.lr, args.impair_epochs)\n",
    "\n",
    "print(\"Performance of Impaired Model on Forget Samples\")\n",
    "test_acc = calculate_accuracy(unsir_model, data_loaders['test'], criterion, args.device)\n",
    "mia_impaired = MIA(unsir_model, data_loaders[\"retain_test\"], data_loaders['forget_test'], data_loaders['test'], args.device)\n",
    "print(f'Test Acc: {test_acc}')\n",
    "print(f'Impaired MIA : {mia_impaired}')\n",
    "\n",
    "# Repair Step\n",
    "repair_step(unsir_model, data_loaders['retain_train'], args.device, args.lr, args.repair_epochs)\n",
    "\n",
    "print(\"Performance of Repaired Model on Forget Samples\")\n",
    "test_acc = calculate_accuracy(unsir_model, data_loaders['test'], criterion, args.device)\n",
    "mia_repaired = MIA(unsir_model, data_loaders[\"retain_test\"], data_loaders['forget_test'], data_loaders['test'], args.device)\n",
    "final_score = (test_acc[\"Acc\"] + 1 - abs(mia_repaired[\"Forgetting Score\"] * 2)) / 2\n",
    "print(f'Test Acc: {test_acc}')\n",
    "print(f'Repaired MIA: {mia_repaired}')\n",
    "print(f'Final score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BadT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Bad Teacher Unlearning ...\n",
      "Epoch 1: train_acc: 35.79, train_loss: -675800.37\n",
      "Epoch 2: train_acc: 30.71, train_loss: -27270869.84\n",
      "Test Acc: {'Loss': 20565.733281237015, 'Acc': 0.42021276595744683, 'Top-2 Acc': 0.6941489361702128}\n",
      "MIA: {'MIA Regression Accuracy': 0.7394396738659034, 'MIA CV Accuracy': 0.5627906976744186, 'Forgetting Score': 0.06279069767441858}\n",
      "Final score: 0.6473156853043048\n"
     ]
    }
   ],
   "source": [
    "from unlearn.badT import badt\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.seed = 42\n",
    "        self.bt_optim = \"adam\"\n",
    "        self.bt_alpha = 1\n",
    "        self.bt_beta = 1\n",
    "        self.bt_kd_T = 4\n",
    "        self.bt_epochs = 2\n",
    "        self.bt_learning_rate = 0.001\n",
    "        self.bt_lr_decay_epochs = [10, 10, 10]\n",
    "        self.bt_lr_decay_rate = 0.1\n",
    "        self.bt_weight_decay = 5e-4\n",
    "        self.bt_momentum = 0.9\n",
    "\n",
    "args = Args()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model_path = 'checkpoint/last_100_age_original.pth'\n",
    "gteacher = load_model(8, args.device, model_path)\n",
    "bteacher = load_model(8, args.device, model_path=None)\n",
    "student = load_model(8, args.device, model_path)\n",
    "\n",
    "badT_model = badt(\n",
    "    gteacher=gteacher,\n",
    "    bteacher=bteacher,\n",
    "    student=student,\n",
    "    retain_loader=data_loaders[\"retain_train\"],\n",
    "    forget_loader=data_loaders[\"forget_train\"],\n",
    "    valid_loader_full=data_loaders[\"test\"],\n",
    "    args=args\n",
    ")\n",
    "\n",
    "test_acc = calculate_accuracy(badT_model, data_loaders['test'], criterion, args.device)\n",
    "mia = MIA(badT_model, data_loaders[\"retain_test\"], data_loaders['forget_test'], data_loaders['test'], args.device)\n",
    "final_score = (test_acc[\"Acc\"] + 1 - abs(mia[\"Forgetting Score\"] * 2)) / 2\n",
    "print(f'Test Acc: {test_acc}')\n",
    "print(f'MIA: {mia}')\n",
    "print(f'Final score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> scrub unlearning ...\n",
      "Epoch 1: maximize loss: -3.10, train_acc: 81.24, minimize loss: 1.67\n",
      "==> scrub unlearning ...\n",
      "Epoch 2: maximize loss: -2.71, train_acc: 82.97, minimize loss: 1.35\n",
      "Total time: 55.80 seconds\n",
      "Test Acc: {'Loss': 0.03583506833603407, 'Acc': 0.6462765957446809, 'Top-2 Acc': 0.8769946808510638}\n",
      "MIA: {'MIA Regression Accuracy': 0.7619047619047619, 'MIA CV Accuracy': 0.6637873754152824, 'Forgetting Score': 0.16378737541528243}\n",
      "Final score: 0.6593509224570581\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from unlearn.scrub import scrub\n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.seed = 42\n",
    "        self.optim = \"sgd\"  \n",
    "        self.sgda_epochs = 2\n",
    "        self.sgda_learning_rate = 0.0005\n",
    "        self.sgda_weight_decay = 5e-4\n",
    "        self.sgda_momentum = 0.9\n",
    "        self.msteps = 2\n",
    "        self.kd_T = 4  \n",
    "        self.lr_decay_epochs = [3, 5, 9]\n",
    "        self.lr_decay_rate = 0.1\n",
    "\n",
    "args = Args()\n",
    "model_path =  'checkpoint/last_100_age_original.pth'\n",
    "teacher_model = load_model(8, args.device, model_path)\n",
    "student_model = load_model(8, args.device, model_path)\n",
    "\n",
    "scrub_model = scrub(\n",
    "    teacher=teacher_model,\n",
    "    student=student_model,\n",
    "    args=args,\n",
    "    retain_loader_train=data_loaders[\"retain_train\"],\n",
    "    retain_loader_test=data_loaders[\"retain_test\"],\n",
    "    forget_loader_train=data_loaders[\"forget_train\"],\n",
    "    forget_loader_test=data_loaders[\"forget_test\"],\n",
    "    valid_loader_full=data_loaders[\"test\"] \n",
    ")\n",
    "\n",
    "test_acc = calculate_accuracy(scrub_model, data_loaders['test'], criterion, args.device)\n",
    "mia = MIA(scrub_model, data_loaders[\"retain_test\"], data_loaders['forget_test'], data_loaders['test'], args.device)\n",
    "final_score = (test_acc[\"Acc\"] + 1 - abs(mia[\"Forgetting Score\"] * 2)) / 2\n",
    "print(f'Test Acc: {test_acc}')\n",
    "print(f'MIA: {mia}')\n",
    "print(f'Final score: {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wg2w3nT-ohvF"
   },
   "source": [
    "### DLFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from unlearn.dlfd import train_dlfd, set_seed, linear_weight_scheduler\n",
    "set_seed(42) \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = 'checkpoint/last_100_age_original.pth'\n",
    "dlfm_model = load_model(8, device, model_path)\n",
    "path = 'checkpoint/age_dlfd.pth'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(dlfm_model.parameters(), lr=0.008, momentum=0.9, weight_decay=5e-4)\n",
    "\n",
    "forget_weight = 3.0  # Weight for forgetting\n",
    "initial_retain_weight = 0  # Initial weight for retaining\n",
    "final_retain_weight = 1  # Final weight for retaining\n",
    "perturbation_steps = 15  # Number of steps for perturbation\n",
    "perturbation_strength = 0.4  # Strength of perturbation\n",
    "forget_threshold = 0.15  # Forgetting score threshold\n",
    "best_test_acc = 0  # Save the best test accuracy\n",
    "max_forgetting_score = 0.09  # Forgetting score saving threshold\n",
    "\n",
    "train_dlfd(\n",
    "        dlfm_model, data_loaders, criterion, optimizer, device,\n",
    "        perturbation_steps, perturbation_strength, forget_threshold, max_forgetting_score,\n",
    "        initial_retain_weight, final_retain_weight, forget_weight, path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: {'Loss': 0.03269348626441144, 'Acc': 0.6196808510638298, 'Top-2 Acc': 0.8736702127659575}\n",
      "MIA :{'MIA Regression Accuracy': 0.7411744296990198, 'MIA CV Accuracy': 0.527906976744186, 'Forgetting Score': 0.027906976744185963}\n",
      "Final score: 0.781933448787729\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_path = 'checkpoint/age_dlfd.pth'\n",
    "dlfm_model = load_model(8, device, model_path)\n",
    "\n",
    "test_acc = calculate_accuracy(dlfm_model, data_loaders['test'], criterion, device)\n",
    "mia = MIA(dlfm_model, data_loaders[\"retain_test\"], data_loaders['forget_test'], data_loaders['test'], device)\n",
    "final_score = (test_acc[\"Acc\"] + 1 - abs(mia[\"Forgetting Score\"] * 2)) / 2\n",
    "print(f'Test Acc: {test_acc}')\n",
    "print(f'MIA :{mia}')\n",
    "print(f'Final score: {final_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0d452e1ccff24c37949ccf6a7abe25a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f0b7af470ea54f9ab03b9f42cbdf44ef",
       "IPY_MODEL_8ea957f70478483595351f565cbf5349",
       "IPY_MODEL_f691d3cd77d648c68f2762630527bfd1"
      ],
      "layout": "IPY_MODEL_a8ab248854344c77a71b4fae32d5f2a3"
     }
    },
    "400561172afd4e4aa350ac66c731fbb2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46977e9702d24d119608416d8e1d5c27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "82a3a8fdd7f9412da687a87d8f1e0549": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ea957f70478483595351f565cbf5349": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82a3a8fdd7f9412da687a87d8f1e0549",
      "max": 21355344,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f813e00353774410b05571e8a77621dc",
      "value": 21355344
     }
    },
    "a8ab248854344c77a71b4fae32d5f2a3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3d24d5d6ba041679f55a438239e3351": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0b7af470ea54f9ab03b9f42cbdf44ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46977e9702d24d119608416d8e1d5c27",
      "placeholder": "​",
      "style": "IPY_MODEL_fe22b0d8233948ec80e95f3c3f15ac8c",
      "value": "model.safetensors: 100%"
     }
    },
    "f691d3cd77d648c68f2762630527bfd1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_400561172afd4e4aa350ac66c731fbb2",
      "placeholder": "​",
      "style": "IPY_MODEL_b3d24d5d6ba041679f55a438239e3351",
      "value": " 21.4M/21.4M [00:02&lt;00:00, 9.60MB/s]"
     }
    },
    "f813e00353774410b05571e8a77621dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fe22b0d8233948ec80e95f3c3f15ac8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
